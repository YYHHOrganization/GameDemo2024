//this is Mobile + Non-Mobile separated implementations of "Screen Space Planar Reflections in Ghost Recon Wildlands" using a single URP RendererFeature
//http://remi-genin.fr/blog/screen-space-plane-indexed-reflection-in-ghost-recon-wildlands/

//*we don't sample fallback reflection probe here, we sample it inside user's shader (e.g. water plane shader)
//because Lighting data provided by URP (e.g. reflection probe) is only correct when rendering using normal drawing method, but not correct in compute shader

//NUMTHREAD_X * NUMTHREAD_Y must be multiple of 64 and <= 256 to balance between performance and mobile support, so we use 8*8
#define NUMTHREAD_X 8
#define NUMTHREAD_Y 8

#define MAX_UINT 4294967295

#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

//common uniform input from MobileSSPRRendererFeature.cs
float2 _RTSize;
float _HorizontalPlaneHeightWS;
float3 _CameraDirection;
float _FadeOutScreenBorderWidthVerticle;
float _FadeOutScreenBorderWidthHorizontal; //compute shader can't declare half type input, so use float
float4 _FinalTintColor;

//we found that on metal, UNITY_MATRIX_VP is not correct, so we will pass our own VP matrix to compute shader
//but UNITY_MATRIX_I_VP is correct, not sure why.
float4x4 _VPMatrix;
float _ScreenLRStretchIntensity;
float _ScreenLRStretchThreshold;

//common texture input from MobileSSPRRendererFeature.cs
RWTexture2D<half4> ColorRT;
Texture2D<half4> _CameraOpaqueTexture;
Texture2D<float> _CameraDepthTexture;

//common SamplerState settings
SamplerState PointClampSampler;
SamplerState LinearClampSampler;

//Non-Mobile path will use this RT: single 32bits RInt RT, split first 16bits for GetReflectionColorFromID's y, last 16bits for GetReflectionColorFromID's x
//y put in first 16 bits because we want to sort by InterlockedMin(), allowing only "closer to reflection plane candidate" to write to HashRT
RWTexture2D<uint> HashRT;

////////////////////////////////////////////////////////////////////////////////////////////////////
// shared functions
////////////////////////////////////////////////////////////////////////////////////////////////////
float3 ConvertScreenIDToPosWS(uint3 id)
{
    /*
     * note：记住这个转换方式，在Compute Shader中后面也可以继续使用
     * 看下面的代码，我的理解是深度图采样得到的深度是裁剪空间的
     * 通过把裁剪空间的深度和屏幕uv坐标，通过逆矩阵的方式，转换到世界坐标，这样就可以得到世界坐标了
     **/
    //input id is compute function's input SV_DispatchThreadID
    float2 screenUV = float2(id.x / (_RTSize.x), id.y / (_RTSize.y)); //[0,RTSize-1] -> screen [0,1] uv
    float inputPixelRawDepth = _CameraDepthTexture.SampleLevel(PointClampSampler, screenUV, 0);//get rawDepth(posCS.z) in _CameraDepthTexture,这个根据前面的学习应该是裁剪空间的，最后一个参数0表示不使用mip
    ////////////////////////////////////////////////////////////////////////////////////////////////////
    //convert screenUV & _CameraDepthTexture's rawDepth(posCS.z) to posWS
    //https://github.com/Steven-Cannavan/URP_ScreenSpacePlanarReflections/blob/master/Assets/Shaders/ReflectionShader.compute#L75
    ////////////////////////////////////////////////////////////////////////////////////////////////////
    float4 posCS = float4(screenUV * 2.0 - 1.0, inputPixelRawDepth, 1.0); //reconstruct posCS using screen [0,1] uv & rawDepth
    #if UNITY_UV_STARTS_AT_TOP
        posCS.y = -posCS.y;
    #endif
    float4 posHWS = mul(UNITY_MATRIX_I_VP, posCS); //posCS -> posHWS
    float3 posWS = posHWS.xyz / posHWS.w; //posHWS -> posWS,归一化处理
    return posWS;
}

float3 MirrorPosWS(float3 inputPosWS)
{
    float3 reflectedPosWS = inputPosWS;
    reflectedPosWS.y -= _HorizontalPlaneHeightWS;  // y - h 
    reflectedPosWS.y *= -1;//actual reflect action // h - y
    reflectedPosWS.y += _HorizontalPlaneHeightWS; // 2h - y

    return reflectedPosWS;
}

float2 ConvertReflectedPosWSToScreenUV(float3 reflectedPosWS)
{
    //todo:现在只是单纯的转换，会有一些视觉上的issue，需要做stretch等操作
    ////////////////////////////////////////////////////////////////////////////////////////////////////
    //find reflected posWS's new screenUV
    //https://github.com/Steven-Cannavan/URP_ScreenSpacePlanarReflections/blob/master/Assets/Shaders/ReflectionShader.compute#L87
    ////////////////////////////////////////////////////////////////////////////////////////////////////
    float4 reflectedPosCS = mul(_VPMatrix, float4(reflectedPosWS, 1));//posWS -> posCS
    float2 reflectedPosNDCxy = reflectedPosCS.xy / reflectedPosCS.w;//posCS -> posNDC
    float2 reflectedScreenUV = reflectedPosNDCxy * 0.5 + 0.5; //posNDC -> screen [0,1] uv, don't saturate() to allow  out of bound access early exit
    ////////////////////////////////////////////////////////////////////////////////////////////////////
    //fix left right missing geometry 
    //ref: http://remi-genin.fr/blog/screen-space-plane-indexed-reflection-in-ghost-recon-wildlands/#filling-the-gaps-jump
    ////////////////////////////////////////////////////////////////////////////////////////////////////
    //sample code from http://remi-genin.fr/blog/screen-space-plane-indexed-reflection-in-ghost-recon-wildlands/#filling-the-gaps-jump
    /*
    float HeightStretch = (PosWS.z - WaterHeight);
    float AngleStretch = saturate(- CameraDirection.z);
    float ScreenStretch = saturate(abs(ReflPosUV.x * 2 - 1) - Threshold);

    ReflPosUV.x *= 1 + HeightStretch * AngleStretch * ScreenStretch * Intensity;
    */
    float Threshold = _ScreenLRStretchThreshold;
    float Intensity = _ScreenLRStretchIntensity;
    float HeightStretch = (abs(reflectedPosWS.y - _HorizontalPlaneHeightWS));
    float AngleStretch = (-_CameraDirection.y);
    float ScreenStretch = saturate(abs(reflectedScreenUV.x * 2 - 1) - Threshold);
    
    reflectedScreenUV.x = reflectedScreenUV.x * 2 - 1;
    reflectedScreenUV.x *= 1 + HeightStretch * AngleStretch * ScreenStretch * Intensity;
    reflectedScreenUV.x = saturate(reflectedScreenUV.x * 0.5 + 0.5);

    #if UNITY_UV_STARTS_AT_TOP
        reflectedScreenUV.y = 1.0 - reflectedScreenUV.y;
    #endif
    return reflectedScreenUV;
}

half ConvertOpaqueColorRTScreenUVToFadeAlphaParam(float2 screenUV, float reflectedPosWSy)
{
    //fadeout  using vertical uv.y (only fadeout if reaching _CameraOpaqueTexture's uv border top)
    half fadeoutAlpha = smoothstep(1, 1-_FadeOutScreenBorderWidthVerticle, screenUV.y);
    //fadeout using horizontal uv.x
    //TODO: better fadeout
    fadeoutAlpha *= smoothstep(1, 1 - _FadeOutScreenBorderWidthHorizontal * -(reflectedPosWSy-_HorizontalPlaneHeightWS), abs(screenUV.x * 2 - 1));
    return fadeoutAlpha;
}

////////////////////////////////////////////////////////////////////////////////////////////////////
// kernel: NonMobilePathClear
////////////////////////////////////////////////////////////////////////////////////////////////////
#pragma kernel NonMobilePathClear

[numthreads(NUMTHREAD_X, NUMTHREAD_Y, 1)]
void NonMobilePathClear(uint3 id : SV_DispatchThreadID)
{
    HashRT[id.xy] = MAX_UINT; //max value as clear, because we want to sort by InterlockedMin()
    ColorRT[uint2(id.xy)] = half4(0, 0, 0, 0);
}

////////////////////////////////////////////////////////////////////////////////////////////////////
// kernel: NonMobilePathRenderHashRT
////////////////////////////////////////////////////////////////////////////////////////////////////
#pragma kernel NonMobilePathRenderHashRT
[numthreads(NUMTHREAD_X,NUMTHREAD_Y,1)]
void NonMobilePathRenderHashRT(uint3 id : SV_DispatchThreadID)
{
    //step 1: convertScreenIdToWorldPos
    float3 posWS = ConvertScreenIDToPosWS(id);  //使用逆矩阵的方式，将屏幕坐标转换到世界坐标，应该结果比较准确
    
    //step 2: 计算反射的位置
    //if posWS is already under reflection plane (e.g. under water plane), 
    //it will never be a correct color to reflect anyway, early exit to prevent wrong result write to Color RT
    if(posWS.y <= _HorizontalPlaneHeightWS)  
        return;
    float3 reflectedPosWS = MirrorPosWS(posWS);

    //step 3: convert reflectedPosWS to screenUV
    float2 reflectedScreenUV = ConvertReflectedPosWSToScreenUV(reflectedPosWS);
    //early exit if not valid uv anymore, to avoid out of bound access
    float2 earlyExitTest = abs(reflectedScreenUV - 0.5);
    if (earlyExitTest.x >= 0.5 || earlyExitTest.y >= 0.5)  //注：原参考程序这里是0.5，但是如果是0.5的话，边缘会clamp到一起，效果很差，改成0.495之后会好一些
        return;
    uint2 reflectedScreenID = reflectedScreenUV * _RTSize;//from screen uv[0,1] to [0,RTSize-1]

    //step 4：为了防止出现Z-fighting，我们使用InterlockedMin()来保证只有最近的反射点才会写入
    //note：这里见笔记
    float2 screenUV = id.xy / _RTSize;
    half fadeoutAlpha = ConvertOpaqueColorRTScreenUVToFadeAlphaParam(screenUV, reflectedPosWS.y);
    uint fadeoutAlphaInt = fadeoutAlpha * 255;//8 bit
    uint hash = id.y << 20 | id.x << 8 | fadeoutAlphaInt; //pack 3 uint into 1,encode

    #if SHADER_API_METAL
    //do nothing because metal will never use this kernel (NonMobile kernel)
    #else
    InterlockedMin(HashRT[reflectedScreenID],hash); //correct sorting method, sort by id.y
    #endif
    //HashRT[reflectedScreenID] = hash; //no sorting method, don't use it, it will produce random flickering because of unknown order write(random order)
}

////////////////////////////////////////////////////////////////////////////////////////////////////
// kernel NonMobilePathResolveColorRT
////////////////////////////////////////////////////////////////////////////////////////////////////
#pragma kernel NonMobilePathResolveColorRT

[numthreads(NUMTHREAD_X, NUMTHREAD_Y, 1)]
void NonMobilePathResolveColorRT(uint3 id : SV_DispatchThreadID)
{
    /*
    //ref code
    //http://remi-genin.fr/blog/screen-space-plane-indexed-reflection-in-ghost-recon-wildlands/#hash-resolve-jump
    
    float4 PS_ResolveHash(float2 ScreenUV) : SV_Target0
    {
        uint Hash = ProjectionHashTex[ScreenUV * FrameSize].x;
        uint x = Hash & 0xFFFF; uint y = Hash >> 16;

        if(Hash != 0)
        {
            float4 SrcColor = MainColorTex[uint2(x, y)];
            return SrcColor;
        }
        else
            return 0;
    }
    */
    uint packedData = HashRT[id.xy];	
    if (packedData == (uint)MAX_UINT) //MAX_UINT == max uint
    {
        //if this location is not having any reflection data (still containing clear value, still 0 reflection write), early exit to prevent wrong RT write
        ColorRT[id.xy] = 0;
        return;
    }
    //ghost-recon-wildlands method use 16bit y, 16bit x encode
    //but in our implementation, 16bit is overkill because we don't need a RT that is 65536*65536
    //instead we save 8 bits for fadeout alpha info, result in:
    //-first 12 bits for id.y (0~4095)
    //-then  12 bits for id.x (0~4095)
    //-last  8  bits for alpha (0~255)
    uint2 sampleID = uint2((packedData >> 8) & 0xFFF, packedData >> 20); //decode from single 32bit uint, to 3 separated uint (12bit y & 12bit x & 8bit alpha)
    uint alphaAsInt = packedData & 0xFF;
    half alphaAsFloatingPoint = alphaAsInt / 255.0;

    float2 sampleUV = sampleID.xy / _RTSize;
    half3 sampledColor = _CameraOpaqueTexture.SampleLevel(LinearClampSampler, sampleUV, 0);

    half4 finalColor = half4(sampledColor, alphaAsFloatingPoint) * _FinalTintColor;
    finalColor.a = saturate(finalColor.a);
    ColorRT[id.xy] = finalColor;
}

////////////////////////////////////////////////////////////////////////////////////////////////////
// kernel FillHoles
////////////////////////////////////////////////////////////////////////////////////////////////////
#pragma kernel FillHoles

[numthreads(NUMTHREAD_X, NUMTHREAD_Y, 1)]
void FillHoles(uint3 id : SV_DispatchThreadID)
{
    //我的理解这个kernel的核心思路是试图依据周围像素把那些黑色的像素点填充上，这样就不会出现黑色的洞了
    //fill holes inside each 2*2
    id.xy *= 2;

    //cache read
    half4 center = ColorRT[id.xy + uint2(0, 0)];
    half4 right = ColorRT[id.xy + uint2(0, 1)];
    half4 bottom = ColorRT[id.xy + uint2(1, 0)];
    half4 bottomRight = ColorRT[id.xy + uint2(1, 1)];

    //find best inside 2*2
    //通过比较透明度（alpha 值），检查右侧、底部和右下角的像素。如果其中某个像素的 alpha 值大于 best 的 alpha 值加上 0.5，那么更新 best 为该像素。这一步的目的是找到最适合用于填补当前空洞的颜色。
    half4 best = center;
    best = right.a > best.a + 0.5 ? right : best;
    best = bottom.a > best.a + 0.5 ? bottom : best;
    best = bottomRight.a > best.a + 0.5 ? bottomRight : best;

    //write better rgba
    //最后，将计算出的最佳颜色值写入 ColorRT 的相应位置。如果 best 的 alpha 值比当前像素的 alpha 值大 0.5，则用 best 来替换当前像素，否则保留原来的像素。这确保了只有当新候选显著优于现有像素时才会进行更新。
    ColorRT[id.xy + uint2(0, 0)] = best.a > center.a + 0.5 ? best : center;
    ColorRT[id.xy + uint2(0, 1)] = best.a > right.a + 0.5 ? best : right;
    ColorRT[id.xy + uint2(1, 0)] = best.a > bottom.a + 0.5 ? best : bottom;
    ColorRT[id.xy + uint2(1, 1)] = best.a > bottomRight.a + 0.5 ? best : bottomRight;
}

// //kernel gaussian blur result
// #pragma kernel GaussianBlur
// void GaussianBlur(uint3 id : SV_DispatchThreadID)
// {
//     
// }